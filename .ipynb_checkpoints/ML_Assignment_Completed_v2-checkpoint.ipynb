{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Assignment 1\n",
    "\n",
    "## Naive Bayes Learning algorithm, Cross-validation, and ROC-Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the assignment is to implement:\n",
    "\n",
    "* Naive Bayes learning algorithm for binary classification tasks\n",
    "* Visualization to plot a ROC-curve\n",
    "* A cross-validation test\n",
    "* Visualization of the average ROC-curve of a cross-validation test\n",
    "\n",
    "Follow the instructions and implement what is missing to complete the assignment. Some functions have been started to help you a little bit with the inputs or outputs of the function.\n",
    "\n",
    "**Note:** You might need to go back and forth during your implementation of the code. The structure is set up to make implementation easier, but how you return values from the different functions might vary, and you might find yourself going back and change something to make it easier later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We help you out with importing the libraries and reading the data.\n",
    "\n",
    "Look at the output to get an idea of how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import e, pi, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_set:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "        self.means = 0.0\n",
    "        self.prior = 0.0\n",
    "        self.std_devs = 0.0\n",
    "        self.gaussian_probability_density = 0.0\n",
    "\n",
    "    def fix_data_structure(self):\n",
    "        if all(isinstance(row, np.ndarray) for row in self.features):\n",
    "            try:\n",
    "                self.features = np.array(self.features, dtype=float)\n",
    "            except ValueError as e:\n",
    "                print(\"Erreur lors de la conversion :\", e)\n",
    "        else:\n",
    "            print(\"Les éléments ne sont pas tous des tableaux numpy.\")\n",
    "\n",
    "    def class_split(self):\n",
    "        self.features = self.data[:, :-1]\n",
    "        self.labels = self.data[:, -1]\n",
    "        self.fix_data_structure()\n",
    "\n",
    "    def display_features_and_labels(self):\n",
    "        print(\"Features set:\")\n",
    "        print(self.features)\n",
    "        print(\"Labels set:\")\n",
    "        print(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a class to make the code cleaner\n",
    "class Flower:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.train = Data_set()\n",
    "        self.test = Data_set()\n",
    "        self.test_size = 0.2\n",
    "\n",
    "    def train_test_split(self):\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        split_index = int(len(self.data) * (1 - self.test_size))\n",
    "\n",
    "        self.train.data = self.data[:split_index]\n",
    "        self.test.data = self.data[split_index:]\n",
    "\n",
    "    def class_split_automation(self):\n",
    "        self.train.class_split()\n",
    "        self.test.class_split()\n",
    "        self.train.display_features_and_labels()\n",
    "        self.test.display_features_and_labels()\n",
    "\n",
    "    def display_training(self):\n",
    "        print(\"Train set:\")\n",
    "        print(self.train.data[:3])\n",
    "        print(\"Test set:\")\n",
    "        print(self.test.data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data array (features and labels):\n",
      "[[5.1 3.5 1.4 0.2 0]\n",
      " [4.9 3.0 1.4 0.2 0]\n",
      " [4.7 3.2 1.3 0.2 0]]\n",
      "\n",
      "###############\n",
      "\n",
      "Train features (first 4 columns):\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.0 1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n",
      "\n",
      "Labels (last column):\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n",
      "\n",
      "Names of labels:\n",
      "[[0, 'Iris-setosa'], [1, 'Iris-versicolor'], [2, 'Iris-virginica']]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"iris.csv\").to_numpy()\n",
    "\n",
    "mapped, index, unique_arr = np.unique(data[:, -1], return_index=True, return_inverse=True)\n",
    "data[:, -1] = unique_arr\n",
    "\n",
    "iris_setosa = Flower()\n",
    "iris_versicolor = Flower()\n",
    "iris_virginica = Flower()\n",
    "\n",
    "iris_setosa.data, iris_versicolor.data, iris_virginica.data = np.split(data, index[1:])\n",
    "\n",
    "print(f\"Full data array (features and labels):\\n{iris_setosa.data[:3]}\\n\")\n",
    "print(\"###############\\n\")\n",
    "print(f\"Train features (first 4 columns):\\n{iris_setosa.data[:3, :-1]}\\n\")\n",
    "print(f\"Labels (last column):\\n{iris_setosa.data[:3, -1:]}\\n\")\n",
    "print(f\"Names of labels:\\n{[[numb, name] for numb, name in enumerate(mapped)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0],\n",
       "       [4.9, 3.0, 1.4, 0.2, 0],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example print of the 3 first datapoints (similar as above):\n",
    "iris_setosa.data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling functions\n",
    "\n",
    "As a start, we are going to implement some basic data handling functions to use in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Split class into a train and test set\n",
    "\n",
    "First, we need to be able to split the class into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "[[4.6 3.4 1.4 0.3 0]\n",
      " [4.9 2.4 3.3 1.0 1]\n",
      " [5.8 2.6 4.0 1.2 1]]\n",
      "Test set:\n",
      "[[6.0 2.7 5.1 1.6 1]\n",
      " [5.1 2.5 3.0 1.1 1]\n",
      " [5.0 3.0 1.6 0.2 0]]\n",
      "Train set:\n",
      "[[6.4 2.7 5.3 1.9 2]\n",
      " [5.2 4.1 1.5 0.1 0]\n",
      " [6.0 3.4 4.5 1.6 1]]\n",
      "Test set:\n",
      "[[6.3 3.4 5.6 2.4 2]\n",
      " [4.4 2.9 1.4 0.2 0]\n",
      " [6.7 3.1 5.6 2.4 2]]\n",
      "Train set:\n",
      "[[6.2 2.8 4.8 1.8 2]\n",
      " [5.5 2.4 3.7 1.0 1]\n",
      " [6.2 3.4 5.4 2.3 2]]\n",
      "Test set:\n",
      "[[5.1 3.8 1.9 0.4 0]\n",
      " [5.7 3.8 1.7 0.3 0]\n",
      " [6.6 2.9 4.6 1.3 1]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test the train_test_split function\n",
    "iris_setosa.train_test_split()\n",
    "iris_versicolor.train_test_split()\n",
    "iris_virginica.train_test_split()\n",
    "\n",
    "# TODO: Print the output\n",
    "iris_setosa.display_training()\n",
    "iris_versicolor.display_training()\n",
    "iris_virginica.display_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Split data into features and labels\n",
    "\n",
    "The data as shown above is not always the optimal shape. To help us keep track of things, we can split the data into its features and labels seperately.\n",
    "\n",
    "Each class is 4 features and 1 label in the same array: \n",
    "\n",
    "* **[feature 1, feature 2, feature 3, feature 4, label]**\n",
    "\n",
    "It would help us later to have the features and labels in seperate arrays in the form: \n",
    "\n",
    "* **[feature 1, feature 2, feature 3, feature 4]** and **[label]**\n",
    "\n",
    "Here you are going to implement this functionallity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should first test the \"**class_split**\" function on one of the classes above (iris_setosa, etc...) to make sure it works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features set:\n",
      "[[4.6 3.4 1.4 0.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [7.4 2.8 6.1 1.9]]\n",
      "Labels set:\n",
      "[0 1 1 2 1 2 1 2 1 1 0 2 1 1 2 1 2 0 0 0 2 1 1 2 2 1 2 1 0 0 1 0 1 2 1 2 0\n",
      " 0 2 2]\n",
      "Features set:\n",
      "[[6.  2.7 5.1 1.6]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.  3.  1.6 0.2]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.7 3.  5.  1.7]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.8 2.7 4.1 1. ]]\n",
      "Labels set:\n",
      "[1 1 0 2 1 2 0 2 2 1]\n",
      "Features set:\n",
      "[[6.4 2.7 5.3 1.9]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.  2.2 4.  1. ]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.8 2.7 3.9 1.2]]\n",
      "Labels set:\n",
      "[2 0 1 1 0 1 2 1 1 0 0 2 2 0 0 0 1 2 1 2 1 1 1 2 1 1 1 1 2 0 2 2 2 1 2 0 0\n",
      " 1 2 1]\n",
      "Features set:\n",
      "[[6.3 3.4 5.6 2.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.7 2.5 5.8 1.8]]\n",
      "Labels set:\n",
      "[2 0 2 2 2 0 0 1 2 2]\n",
      "Features set:\n",
      "[[6.2 2.8 4.8 1.8]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.4 3.  1.3 0.2]]\n",
      "Labels set:\n",
      "[2 1 2 1 0 0 2 0 0 1 0 0 0 1 2 0 0 0 2 0 1 0 0 0 1 2 2 0 1 1 0 0 0 0 0 2 1\n",
      " 2 0 0]\n",
      "Features set:\n",
      "[[5.1 3.8 1.9 0.4]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.  2.3 3.3 1. ]]\n",
      "Labels set:\n",
      "[0 0 1 1 2 2 0 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test the class splitting function\n",
    "# iris_setosa.train.class_split()\n",
    "# iris_setosa.test.class_split()\n",
    "\n",
    "# iris_versicolor.train.class_split()\n",
    "# iris_versicolor.test.class_split()\n",
    "\n",
    "# iris_virginica.train.class_split()\n",
    "# iris_virginica.test.class_split()\n",
    "\n",
    "# TODO: Print the output\n",
    "# iris_setosa.train.display_features_and_labels()\n",
    "# iris_setosa.test.display_features_and_labels()\n",
    "\n",
    "# iris_versicolor.train.display_features_and_labels()\n",
    "# iris_versicolor.test.display_features_and_labels()\n",
    "\n",
    "# iris_virginica.train.display_features_and_labels()\n",
    "# iris_virginica.test.display_features_and_labels()\n",
    "\n",
    "# Or \n",
    "\n",
    "iris_setosa.class_split_automation()\n",
    "iris_versicolor.class_split_automation()\n",
    "iris_virginica.class_split_automation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also try to **1)** first split a class into a train and test set, **2)** split each of these two into features and abels. In total there should be 4 arrays (2 feature and 2 label arrays)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Think a bit before going to the next task, what can easily go wrong in the above code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implementing the Navie Bayes learning algorithm, we can break it down into a few components.\n",
    "\n",
    "We will implement these components one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Calculate feature statistics\n",
    "\n",
    "First, we need to implement a function that returns feature statistics (means, standard deviation, priors) for a given set of feature data for a single class. This is the equivalent of \"training\" the naive bayes model.\n",
    "\n",
    "**Note 1:** Each feature gets its own mean and standard deviation!\n",
    "\n",
    "**Note 2:** The way you structure the functions (what is returned) shapes the remainder of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_statistics(data, total):\n",
    "    data = [[float(value) for value in row] for row in data]\n",
    "\n",
    "    means = [sum(feature_column) / len(feature_column) for feature_column in zip(*data)]\n",
    "    \n",
    "    \n",
    "    std_devs = [\n",
    "        (sum((x - mean) ** 2 for x in feature_column) / (len(feature_column) - 1)) ** 0.5\n",
    "        for feature_column, mean in zip(zip(*data), means)\n",
    "    ]\n",
    "    \n",
    "    prior = len(data) / len(total)\n",
    "    \n",
    "    return means, std_devs, prior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the function works, we should test it before proceding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature [[4.6 3.4 1.4 0.3]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [7.4 2.8 6.1 1.9]]\n",
      "means [5.995000000000001, 3.09, 4.095000000000001, 1.295]\n",
      "std_devs [0.855734801957973, 0.4447990038727086, 1.6906909526687297, 0.7059999273625299]\n",
      "prior 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make sure to use our previous class splitting function.\n",
    "# print(type(iris_setosa.train.features), iris_setosa.train.features)\n",
    "\n",
    "# TODO: Test the function here for one of the dataset classes. \n",
    "iris_setosa.train.means, iris_setosa.train.std_devs, iris_setosa.train.prior = calculate_feature_statistics(iris_setosa.train.features, data)\n",
    "iris_versicolor.train.means, iris_versicolor.train.std_devs, iris_versicolor.train.prior = calculate_feature_statistics(iris_versicolor.train.features, data)\n",
    "iris_virginica.train.means, iris_virginica.train.std_devs, iris_virginica.train.prior = calculate_feature_statistics(iris_virginica.train.features, data)\n",
    "\n",
    "# TODO: Print the output from the feature statistic function.\n",
    "print(\"feature\", iris_setosa.train.features)\n",
    "print(\"means\", iris_setosa.train.means)\n",
    "print(\"std_devs\", iris_setosa.train.std_devs) \n",
    "print(\"prior\", iris_setosa.train.prior) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Gaussian probability density function (Gaussian PDF)\n",
    "\n",
    "Now we need to implement the gaussian probability density function to use for a single datapoint.\n",
    "\n",
    "**Note:** Look at the imports in the first cell at the top, it has some math numbers for easy use here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_probability_density_function(x, mean, stdev):\n",
    "    exponent = math.exp(-((x - mean) ** 2) / (2 * (stdev ** 2)))\n",
    "    coefficient = 1 / (math.sqrt(2 * math.pi * (stdev ** 2)))\n",
    "    return coefficient * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Testing Gaussian PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should test it to make sure it works. Train it, using the \"calculate_feature_statistics\" function, on one of the dataset classes. Then, take one datapoint from the same class and use naive bayes gaussian to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to Ellipsis (2628069993.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ... = calculate_feature_statistics(...)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to Ellipsis\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement the code below to test the \"gaussian_probability_density_function\" function for one of the classes.\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Test with one datapoint from the learned class.\n",
    "\n",
    "iris_setosa.train.gaussian_probability_density = gaussian_probability_density_function()\n",
    "iris_versicolor.train.gaussian_probability_density = gaussian_probability_density_function()\n",
    "iris_virginica.train.gaussian_probability_density = gaussian_probability_density_function()\n",
    "\n",
    "# TODO: Print the probability density\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test, take one datapoint from one of the other classes and see if the predicted probability changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Take one datapoint from one of the other classes.\n",
    "other_class_datapoint = ...\n",
    "\n",
    "# TODO: Use naive bayes gaussian on this datapoint with the same feature statistics as the first class.\n",
    "... = gaussian_probability_density_function(...)\n",
    "\n",
    "# TODO: Print the probability\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think a bit why the probability changes, what could affect the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Naive Bayes for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Prepare the data for inference\n",
    "\n",
    "Before we train and test the naive bayes for multiple classes, we should get our data in order.\n",
    "\n",
    "Similar to how we did previously, we should now split two classes into a train and test set, you may choose which two classes freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split two classes into train and test sets.\n",
    "\n",
    "\n",
    "# TODO: Sepearte the features and lables for both the train and test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Class A vs Class B for binary classification\n",
    "\n",
    "**Note:** You might need to go back and forth a bit in the following cells during your implementation of your code.\n",
    "\n",
    "We have to get the probability from two sets of classes and compare the two probabilities in order to make a propper prediction.\n",
    "\n",
    "Here we will implement two functions to make this possible. We seperate these functions to make the implementation of the ROC-curve easier later on.\n",
    "\n",
    "**Function 1: naive_bayes_prediction** \n",
    "* A function that returns the probabilities for each class the model for a single datapoint.\n",
    "\n",
    "**Function 2: probabilities_to_prediction**\n",
    "* A function that takes in probabilities and returns a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_prediction(feature_stats, data_point):\n",
    "\n",
    "    # TODO: Implement the rest of this function. Make use of previous functions that you have implemented.\n",
    "\n",
    "\n",
    "    # Note: We need to compare the probabilities at some point between the classes we test on, the predicted class should be the class with the highest probability.\n",
    "    return prediction_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_to_prediction(probabilities):\n",
    "\n",
    "    # TODO: Implement prediction of the class with the highest probability\n",
    "\n",
    "    return class_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function we need the feature metrics from the classes we choose. \n",
    "\n",
    "**Note:** Choose the correct train/test set and the correct feature/label split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the feature metrics for the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have implemented all the neccessary parts to train a naive bayes algorithm and do inference on it. Implement a small test workflow for two of your chosen classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the \"naive_bayes_prediction\" function and implement all neccessary code for it to work.\n",
    "\n",
    "# TODO: Print the predicted class and the actual class for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-curve\n",
    "\n",
    "A ROC curve, or *Receiver Operating Characteristic curve*, is a graphical plot that illustrates the performance of a binary classifier such as our Naive Bayes model.\n",
    "\n",
    "More info can be found in the course material and here: [https://en.wikipedia.org/wiki/Receiver_operating_characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "\n",
    "Another good illustration by Google can be found here: [https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n",
    "\n",
    "Now that we have a prediction model, we would want to try it out and test it using a ROC-curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) True Positive Rate (TPR) and False Positive Rate (FPR)\n",
    "\n",
    "From our prediction function we get probabilities, and for prediction purposes we have just predicted the one with the highest probability.\n",
    "\n",
    "To plot a ROC-curve, we need the TPR and FPR for the binary classification. We will implement this here.\n",
    "\n",
    "**Note 1:** The threshold is is a value that goes from 0 to 1. \n",
    "\n",
    "**Note 2:** One of the two classes will be seen as \"the positive class\" (prediction over the threshold) and the other as \"the negative class\" (prediction under the threshold).\n",
    "\n",
    "**Note 3:** The threshold stepsize will decide the size of the returned TPR/FPR list. A value of 0.1 will give 10 elements (0 to 1 in increments of 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepsize demonstration\n",
    "print(\"Python list:\", [x/10 for x in range(0,10,1)])\n",
    "\n",
    "# Stepsize demonstration with numpy:\n",
    "print(\"Numpy linspace:\", np.linspace(0,1,11))\n",
    "print(\"Numpy linspace (no endpoint):\", np.linspace(0,1,10,endpoint=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPR_and_FPR(prediction_probabilities, test_labels, threshold_stepsize = 0.1):\n",
    "\n",
    "    # TODO: Implement the rest of this function\n",
    "\n",
    "    TPR = ...\n",
    "    FPR = ...\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the \"TPR_and_FPR\" function on the model you have created previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the values change if you change the threshold stepsize? \n",
    "\n",
    "How does the values change if you change the classes you compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Plot the TPR and FPR\n",
    "\n",
    "To better see what is going on, we can plot the TPR and FPR. We can also calculate the Area Under the ROC Curve (AUC or AUROC) at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(TPR, FPR):\n",
    "\n",
    "    # TODO: Calculate the AUC score.\n",
    "\n",
    "    # TODO: Plot the TPR and FPR using plt (matplotlib)\n",
    "\n",
    "    # TODO: Add a \"middle-line\" in the plot. This can be seen as the \"better/worse than random\" line.\n",
    "\n",
    "    plt.plot(...)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    pass # No need to return anything, remove this line once you are finished implementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the plotting function on the TPR and FPR you just calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "The final task is to take everything you have implemented so far and apply it in a cross-validation loop.\n",
    "\n",
    "**Note 1:** To better reflect a real scenarios, you should shuffle the data before doing cross-validation.\n",
    "\n",
    "**Note 2:** When using cross-validation, the interesting thing is the mean performance (mean AUC, mean accuracy, mean ROC-curve).\n",
    "\n",
    "**Note 3:** This part is a bit more free in terms of implementation, but make sure to use some of the previously implemented functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Cross-validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, target, folds = 10, threshold_stepsize = 0.1):\n",
    "\n",
    "    # TODO: Implement Cross-validation\n",
    "    \n",
    "    for i in range(folds):\n",
    "\n",
    "\n",
    "        ...\n",
    "\n",
    "    # TODO: Plot the average ROC-curve.\n",
    "    # NOTE: Take the correct average!\n",
    "\n",
    "    plot_ROC(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11) 10-fold Cross-validation on all classes\n",
    "\n",
    "Test the \"cross_validation\" function on all the classes against eachother using 10 folds.\n",
    "\n",
    "* Iris-setosa vs Iris-versicolor\n",
    "* Iris-setosa vs Iris-virginica\n",
    "* Iris-versicolor vs Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and test cross-validation function on all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and test cross-validation function on all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and test cross-validation function on all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions for examination:\n",
    "\n",
    "In addition to completing the assignment with all its tasks, you should also prepare to answer the following questions:\n",
    "\n",
    "1) Why is it called \"naive bayes\"?\n",
    "\n",
    "2) What are some downsides of the naive bayes learning algorithm?\n",
    "\n",
    "3) When using ROC-curves, what is the theoretical best and worst result you can get?\n",
    "\n",
    "4) When using ROC-curves, in this assignment for example, is a higher threshold-stepsize always better?  \n",
    "\n",
    "5) When using cross-validation and ROC-curves, why is it important to take the correct mean values? What could go wrong?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished!\n",
    "\n",
    "Was part of the setup incorrect? Did you spot any inconsistencies in the assignment? Could something improve?\n",
    "\n",
    "If so, please write them and send via email and send it to:\n",
    "\n",
    "* marcus.gullstrand@ju.se\n",
    "\n",
    "Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.feature_stats = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains the Naive Bayes classifier using the training data.\n",
    "\n",
    "        Args:\n",
    "            X (ndarray): Features array.\n",
    "            y (ndarray): Labels array.\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        for cls in classes:\n",
    "            # Filter data points for the current class\n",
    "            X_cls = X[y == cls]\n",
    "            \n",
    "            # Compute prior probability for the class\n",
    "            self.class_priors[cls] = len(X_cls) / len(X)\n",
    "            \n",
    "            # Compute mean and variance for each feature in the class\n",
    "            self.feature_stats[cls] = {\n",
    "                \"mean\": np.mean(X_cls, axis=0),\n",
    "                \"variance\": np.var(X_cls, axis=0) + 1e-6  # Avoid division by zero\n",
    "            }\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class labels for the given input features.\n",
    "\n",
    "        Args:\n",
    "            X (ndarray): Features array.\n",
    "\n",
    "        Returns:\n",
    "            predictions (ndarray): Predicted class labels.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            class_probs = {}\n",
    "            for cls in self.class_priors:\n",
    "                # Compute the log-likelihood for each class\n",
    "                mean = self.feature_stats[cls][\"mean\"]\n",
    "                variance = self.feature_stats[cls][\"variance\"]\n",
    "                log_likelihood = -0.5 * np.sum(((x - mean) ** 2) / variance + np.log(2 * np.pi * variance))\n",
    "                class_probs[cls] = np.log(self.class_priors[cls]) + log_likelihood\n",
    "            \n",
    "            # Choose the class with the highest probability\n",
    "            predictions.append(max(class_probs, key=class_probs.get))\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e34728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def cross_validation_with_roc(classifier, X, y, k=5):\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation and calculates ROC curves for each fold.\n",
    "    \n",
    "    Args:\n",
    "        classifier: The Naive Bayes classifier instance.\n",
    "        X (ndarray): Features array.\n",
    "        y (ndarray): Labels array.\n",
    "        k (int): Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        mean_accuracy (float): Average accuracy across folds.\n",
    "        roc_data (list): ROC data for each fold (FPR, TPR, AUC).\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    roc_data = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # Split the data into training and testing for this fold\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Train the classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_scores = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy for this fold\n",
    "        accuracies.append(np.mean(y_scores == y_test))\n",
    "\n",
    "        # Calculate ROC curve and AUC for this fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_data.append((fpr, tpr, roc_auc))\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    return mean_accuracy, roc_data\n",
    "\n",
    "def plot_mean_roc_curve(roc_data):\n",
    "    \"\"\"\n",
    "    Plots the mean ROC curve from cross-validation results.\n",
    "    \n",
    "    Args:\n",
    "        roc_data (list): ROC data for each fold (FPR, TPR, AUC).\n",
    "    \"\"\"\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    for fpr, tpr, roc_auc in roc_data:\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Mean ROC (AUC = {mean_auc:.2f} ± {std_auc:.2f})', lw=2)\n",
    "    plt.fill_between(mean_fpr, \n",
    "                     np.maximum(mean_tpr - np.std(tprs, axis=0), 0), \n",
    "                     np.minimum(mean_tpr + np.std(tprs, axis=0), 1), \n",
    "                     color='grey', alpha=0.2, label='± 1 Std. Dev.')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Mean ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Preparing the data for cross-validation\n",
    "X_full = flower.data[:, :-1].astype(float)\n",
    "y_full = np.array([1 if label == \"Iris-setosa\" else 0 for label in flower.data[:, -1]])\n",
    "\n",
    "# Performing cross-validation and calculating ROC curves\n",
    "mean_accuracy, roc_data = cross_validation_with_roc(nb_classifier, X_full, y_full, k=5)\n",
    "\n",
    "# Displaying the mean accuracy\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "\n",
    "# Plotting the mean ROC curve\n",
    "plot_mean_roc_curve(roc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def gaussian_pdf(x, mean, variance):\n",
    "    \"\"\"\n",
    "    Calculates the Gaussian probability density function for a given x.\n",
    "    \n",
    "    Args:\n",
    "        x (float or ndarray): Input value(s).\n",
    "        mean (float or ndarray): Mean of the Gaussian distribution.\n",
    "        variance (float or ndarray): Variance of the Gaussian distribution.\n",
    "        \n",
    "    Returns:\n",
    "        float or ndarray: Computed probability density.\n",
    "    \"\"\"\n",
    "    coefficient = 1.0 / math.sqrt(2 * math.pi * variance)\n",
    "    exponent = math.exp(-((x - mean) ** 2) / (2 * variance))\n",
    "    return coefficient * exponent\n",
    "\n",
    "# Testing the Gaussian PDF function\n",
    "sample_x = 5.0\n",
    "sample_mean = 4.98918919\n",
    "sample_variance = 0.1182625\n",
    "\n",
    "# Calculating the probability density for the sample\n",
    "pdf_result = gaussian_pdf(sample_x, sample_mean, sample_variance)\n",
    "pdf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84608ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Class A vs Class B for binary classification\n",
    "def filter_binary_classes(features, labels, class_a, class_b):\n",
    "    \"\"\"\n",
    "    Filters the dataset to only include two classes (binary classification).\n",
    "    \n",
    "    Args:\n",
    "        features (ndarray): Feature array.\n",
    "        labels (ndarray): Labels array.\n",
    "        class_a (str): The first class.\n",
    "        class_b (str): The second class.\n",
    "    \n",
    "    Returns:\n",
    "        filtered_features (ndarray): Features of the two classes.\n",
    "        filtered_labels (ndarray): Labels of the two classes (0 and 1).\n",
    "    \"\"\"\n",
    "    binary_indices = (labels == class_a) | (labels == class_b)\n",
    "    filtered_features = features[binary_indices]\n",
    "    filtered_labels = labels[binary_indices]\n",
    "    binary_labels = np.where(filtered_labels == class_a, 0, 1)  # Map class_a to 0, class_b to 1\n",
    "    return filtered_features, binary_labels\n",
    "\n",
    "# Filter training and testing data for binary classification (e.g., Iris-setosa vs Iris-versicolor)\n",
    "binary_train_features, binary_train_labels = filter_binary_classes(\n",
    "    train_features, train_labels, \"Iris-setosa\", \"Iris-versicolor\"\n",
    ")\n",
    "binary_test_features, binary_test_labels = filter_binary_classes(\n",
    "    test_features, test_labels, \"Iris-setosa\", \"Iris-versicolor\"\n",
    ")\n",
    "\n",
    "# Verifying the filtered data\n",
    "binary_train_features[:3], binary_train_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0744fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_tpr_fpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the True Positive Rate (TPR) and False Positive Rate (FPR).\n",
    "    \n",
    "    Args:\n",
    "        y_true (ndarray): True labels.\n",
    "        y_pred (ndarray): Predicted labels.\n",
    "    \n",
    "    Returns:\n",
    "        tpr (float): True Positive Rate.\n",
    "        fpr (float): False Positive Rate.\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    return tpr, fpr\n",
    "\n",
    "# Train Naive Bayes on the binary dataset\n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.fit(binary_train_features, binary_train_labels)\n",
    "\n",
    "# Predict on the binary test set\n",
    "binary_predictions = nb_classifier.predict(binary_test_features)\n",
    "\n",
    "# Calculate TPR and FPR\n",
    "tpr, fpr = calculate_tpr_fpr(binary_test_labels, binary_predictions)\n",
    "tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tpr_fpr(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Plots the True Positive Rate (TPR) and False Positive Rate (FPR) as an ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        y_true (ndarray): True binary labels.\n",
    "        y_scores (ndarray): Predicted probabilities for the positive class.\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guess')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate predicted probabilities for the positive class\n",
    "binary_test_scores = nb_classifier.predict(binary_test_features)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plot_tpr_fpr(binary_test_labels, binary_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_binary(classifier, X, y, class_a, class_b, k=5):\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation for binary classification and calculates TPR, FPR, and AUC for each fold.\n",
    "    \n",
    "    Args:\n",
    "        classifier: The Naive Bayes classifier instance.\n",
    "        X (ndarray): Features array.\n",
    "        y (ndarray): Labels array.\n",
    "        class_a (str): The first class.\n",
    "        class_b (str): The second class.\n",
    "        k (int): Number of folds for cross-validation.\n",
    "    \n",
    "    Returns:\n",
    "        mean_tpr (float): Mean True Positive Rate across folds.\n",
    "        mean_fpr (float): Mean False Positive Rate across folds.\n",
    "        mean_auc (float): Mean AUC across folds.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # Filter data for binary classification\n",
    "        X_train, y_train = filter_binary_classes(X[train_idx], y[train_idx], class_a, class_b)\n",
    "        X_test, y_test = filter_binary_classes(X[test_idx], y[test_idx], class_a, class_b)\n",
    "        \n",
    "        # Train the classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_scores = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate TPR and FPR\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "\n",
    "    mean_tpr = np.mean([np.mean(tpr) for tpr in tprs])\n",
    "    mean_fpr = np.mean([np.mean(fpr) for fpr in fprs])\n",
    "    mean_auc = np.mean(aucs)\n",
    "    return mean_tpr, mean_fpr, mean_auc\n",
    "\n",
    "# Perform cross-validation for Iris-setosa vs Iris-versicolor\n",
    "mean_tpr, mean_fpr, mean_auc = cross_validation_binary(\n",
    "    nb_classifier, train_features, train_labels, \"Iris-setosa\", \"Iris-versicolor\", k=5\n",
    ")\n",
    "\n",
    "mean_tpr, mean_fpr, mean_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
